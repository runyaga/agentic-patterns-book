"""
Learning and Adaptation Pattern Implementation.

Based on the Agentic Design Patterns book Chapter 9:
Enable agents to improve performance through experience.

Key concepts:
- Few-shot learning: Use successful examples as context
- Experience store: Record outcomes for future reference
- Feedback loop: Refine behavior based on success/failure
- Prompt adaptation: Modify prompts based on learned patterns

This module implements:
- ExperienceStore: Store and retrieve past experiences
- FeedbackLoop: Track success/failure and adjust behavior
- AdaptiveAgent: Agent that learns from examples

Example usage:
    store = ExperienceStore()
    store.add_experience(
        task="summarize", input="...", output="...", success=True
    )
    examples = store.get_relevant_examples("summarize", k=3)
"""

from dataclasses import dataclass
from dataclasses import field
from datetime import datetime
from enum import Enum

from pydantic import BaseModel
from pydantic import Field
from pydantic_ai import Agent
from pydantic_ai import RunContext

from agentic_patterns._models import get_model


# --8<-- [start:models]
class ExperienceType(str, Enum):
    """Type of experience recorded."""

    SUCCESS = "success"
    FAILURE = "failure"
    NEUTRAL = "neutral"


class Experience(BaseModel):
    """A recorded experience from agent interaction."""

    task_type: str = Field(description="Type of task performed")
    input_text: str = Field(description="Input provided to the agent")
    output_text: str = Field(description="Output generated by agent")
    outcome: ExperienceType = Field(description="Outcome of the interaction")
    feedback: str = Field(default="", description="Optional feedback")
    timestamp: datetime = Field(
        default_factory=datetime.now,
        description="When the experience occurred",
    )
    metadata: dict = Field(
        default_factory=dict,
        description="Additional context",
    )


class LearningStats(BaseModel):
    """Statistics about learning progress."""

    total_experiences: int = Field(description="Total recorded experiences")
    successes: int = Field(description="Number of successes")
    failures: int = Field(description="Number of failures")
    success_rate: float = Field(description="Success rate (0-1)")
    task_types: list[str] = Field(
        default_factory=list,
        description="Distinct task types learned",
    )


class FeedbackResult(BaseModel):
    """Result from feedback evaluation."""

    original_output: str = Field(description="Original agent output")
    feedback: str = Field(description="Feedback provided")
    was_helpful: bool = Field(description="Whether feedback was helpful")
    improvement_suggestion: str = Field(
        default="",
        description="Suggestion for improvement",
    )


class AdaptedPrompt(BaseModel):
    """An adapted system prompt based on learning."""

    original_prompt: str = Field(description="Original system prompt")
    adapted_prompt: str = Field(description="Adapted prompt with learnings")
    learnings_applied: list[str] = Field(
        default_factory=list,
        description="What learnings were applied",
    )


@dataclass
class ExperienceStore:
    """
    Store for recording and retrieving agent experiences.

    Enables few-shot learning by storing successful examples that
    can be retrieved as context for future tasks.
    """

    experiences: list[Experience] = field(default_factory=list)
    max_experiences: int = 1000

    def add_experience(
        self,
        task_type: str,
        input_text: str,
        output_text: str,
        outcome: ExperienceType,
        feedback: str = "",
        metadata: dict | None = None,
    ) -> Experience:
        """
        Record a new experience.

        Args:
            task_type: Category of task (e.g., "summarize", "translate").
            input_text: Input provided to the agent.
            output_text: Output generated by the agent.
            outcome: Whether the outcome was success/failure/neutral.
            feedback: Optional feedback about the outcome.
            metadata: Additional context.

        Returns:
            The recorded Experience.
        """
        experience = Experience(
            task_type=task_type,
            input_text=input_text,
            output_text=output_text,
            outcome=outcome,
            feedback=feedback,
            metadata=metadata or {},
        )
        self.experiences.append(experience)

        # Trim if exceeding max
        if len(self.experiences) > self.max_experiences:
            self.experiences = self.experiences[-self.max_experiences :]

        return experience

    def add_success(
        self,
        task_type: str,
        input_text: str,
        output_text: str,
        feedback: str = "",
    ) -> Experience:
        """Record a successful experience."""
        return self.add_experience(
            task_type=task_type,
            input_text=input_text,
            output_text=output_text,
            outcome=ExperienceType.SUCCESS,
            feedback=feedback,
        )

    def add_failure(
        self,
        task_type: str,
        input_text: str,
        output_text: str,
        feedback: str = "",
    ) -> Experience:
        """Record a failed experience."""
        return self.add_experience(
            task_type=task_type,
            input_text=input_text,
            output_text=output_text,
            outcome=ExperienceType.FAILURE,
            feedback=feedback,
        )

    def get_relevant_examples(
        self,
        task_type: str,
        k: int = 3,
        only_successes: bool = True,
    ) -> list[Experience]:
        """
        Get relevant examples for few-shot learning.

        Args:
            task_type: Type of task to find examples for.
            k: Maximum number of examples to return.
            only_successes: Whether to only return successful examples.

        Returns:
            List of relevant Experience objects.
        """
        filtered = [e for e in self.experiences if e.task_type == task_type]

        if only_successes:
            filtered = [
                e for e in filtered if e.outcome == ExperienceType.SUCCESS
            ]

        # Return most recent k examples
        return filtered[-k:]

    def get_stats(self) -> LearningStats:
        """Get learning statistics."""
        successes = sum(
            1 for e in self.experiences if e.outcome == ExperienceType.SUCCESS
        )
        failures = sum(
            1 for e in self.experiences if e.outcome == ExperienceType.FAILURE
        )
        total = len(self.experiences)
        rate = successes / total if total > 0 else 0.0

        task_types = list({e.task_type for e in self.experiences})

        return LearningStats(
            total_experiences=total,
            successes=successes,
            failures=failures,
            success_rate=rate,
            task_types=task_types,
        )

    def get_failure_patterns(self, task_type: str) -> list[str]:
        """
        Get feedback from failed experiences for a task type.

        Args:
            task_type: Type of task to analyze.

        Returns:
            List of failure feedback strings.
        """
        failures = [
            e
            for e in self.experiences
            if e.task_type == task_type and e.outcome == ExperienceType.FAILURE
        ]
        return [e.feedback for e in failures if e.feedback]

    def clear(self) -> None:
        """Clear all experiences."""
        self.experiences = []


@dataclass
class FeedbackLoop:
    """
    Feedback loop for tracking and learning from outcomes.

    Records success/failure patterns and provides insights
    for improving agent behavior.
    """

    store: ExperienceStore = field(default_factory=ExperienceStore)
    improvement_threshold: float = 0.7

    def record_outcome(
        self,
        task_type: str,
        input_text: str,
        output_text: str,
        success: bool,
        feedback: str = "",
    ) -> Experience:
        """
        Record an outcome from an agent interaction.

        Args:
            task_type: Type of task performed.
            input_text: Input provided.
            output_text: Output generated.
            success: Whether the outcome was successful.
            feedback: Optional feedback.

        Returns:
            The recorded Experience.
        """
        outcome = ExperienceType.SUCCESS if success else ExperienceType.FAILURE
        return self.store.add_experience(
            task_type=task_type,
            input_text=input_text,
            output_text=output_text,
            outcome=outcome,
            feedback=feedback,
        )

    def should_adapt(self, task_type: str) -> bool:
        """
        Check if the agent should adapt based on performance.

        Args:
            task_type: Type of task to check.

        Returns:
            True if success rate is below threshold.
        """
        examples = [
            e for e in self.store.experiences if e.task_type == task_type
        ]
        if len(examples) < 5:  # Need minimum data
            return False

        successes = sum(
            1 for e in examples if e.outcome == ExperienceType.SUCCESS
        )
        rate = successes / len(examples)
        return rate < self.improvement_threshold

    def get_improvement_suggestions(self, task_type: str) -> list[str]:
        """
        Get suggestions for improving a task type.

        Args:
            task_type: Type of task to improve.

        Returns:
            List of improvement suggestions from failure feedback.
        """
        return self.store.get_failure_patterns(task_type)

    def get_stats(self) -> LearningStats:
        """Get learning statistics."""
        return self.store.get_stats()


# --8<-- [end:models]


# --8<-- [start:agents]
# Initialize model
model = get_model()


@dataclass
class LearningDeps:
    """Dependencies for learning-enabled agents."""

    store: ExperienceStore
    task_type: str = ""
    use_examples: bool = True
    max_examples: int = 3


# Prompt adapter agent - refines prompts based on learnings
prompt_adapter_agent = Agent(
    model,
    system_prompt=(
        "You are a prompt optimization specialist. Given an original "
        "system prompt and feedback about failures, create an improved "
        "prompt that addresses the issues. Keep the core intent but "
        "add clarifications or constraints to prevent failures."
    ),
    output_type=AdaptedPrompt,
)

# Task agent - performs tasks with few-shot examples via @system_prompt
task_agent: Agent[LearningDeps, str] = Agent(
    model,
    system_prompt=(
        "You are a helpful assistant. Complete the given task. "
        "Use any provided examples as guidance for the expected "
        "format and style of your response."
    ),
    deps_type=LearningDeps,
    output_type=str,
)


@task_agent.system_prompt
def inject_examples(ctx: RunContext[LearningDeps]) -> str:
    """Inject few-shot examples from experience store into system prompt."""
    if not ctx.deps.use_examples or not ctx.deps.task_type:
        return ""

    examples = ctx.deps.store.get_relevant_examples(
        ctx.deps.task_type,
        k=ctx.deps.max_examples,
    )

    if not examples:
        return ""

    lines = ["Here are some successful examples for reference:"]
    for i, ex in enumerate(examples, 1):
        lines.append(f"\nExample {i}:")
        lines.append(f"Input: {ex.input_text[:200]}")
        lines.append(f"Output: {ex.output_text[:200]}")

    return "\n".join(lines)


# Feedback evaluator - assesses feedback quality
feedback_evaluator = Agent(
    model,
    system_prompt=(
        "You are a feedback evaluator. Analyze the feedback provided "
        "for an agent's output and determine if it's helpful for "
        "improvement. Suggest specific improvements if possible."
    ),
    output_type=FeedbackResult,
)
# --8<-- [end:agents]


# --8<-- [start:learning]
def format_examples_as_context(examples: list[Experience]) -> str:
    """
    Format examples as few-shot context.

    Args:
        examples: List of successful examples.

    Returns:
        Formatted string for context injection.
    """
    if not examples:
        return ""

    lines = ["Here are some successful examples:"]
    for i, ex in enumerate(examples, 1):
        lines.append(f"\nExample {i}:")
        lines.append(f"Input: {ex.input_text[:200]}")
        lines.append(f"Output: {ex.output_text[:200]}")

    return "\n".join(lines)


async def run_with_learning(
    task_type: str,
    input_text: str,
    store: ExperienceStore,
    use_examples: bool = True,
) -> tuple[str, Experience | None]:
    """
    Run a task with few-shot learning context.

    The agent uses @system_prompt to inject relevant examples from
    the experience store, enabling few-shot learning.

    Args:
        task_type: Type of task to perform.
        input_text: Input for the task.
        store: Experience store for examples.
        use_examples: Whether to include examples in context.

    Returns:
        Tuple of (output string, recorded experience or None).
    """
    print(f"Running task: {task_type}")

    # Create deps - examples are injected via @system_prompt decorator
    deps = LearningDeps(
        store=store,
        task_type=task_type,
        use_examples=use_examples,
    )

    if use_examples:
        examples = store.get_relevant_examples(task_type, k=3)
        if examples:
            print(f"  Using {len(examples)} examples for context")

    # Run task - examples injected automatically via system prompt
    result = await task_agent.run(input_text, deps=deps)
    output = result.output

    print("  Task complete")

    return output, None


async def process_feedback(
    output: str,
    feedback: str,
) -> FeedbackResult:
    """
    Process feedback about an agent output.

    Args:
        output: The output that received feedback.
        feedback: The feedback provided.

    Returns:
        FeedbackResult with analysis.
    """
    result = await feedback_evaluator.run(
        f"Agent output:\n{output}\n\n"
        f"Feedback received:\n{feedback}\n\n"
        f"Analyze this feedback and determine if it's helpful."
    )
    return result.output


async def adapt_prompt(
    original_prompt: str,
    failure_feedback: list[str],
) -> AdaptedPrompt:
    """
    Adapt a system prompt based on failure feedback.

    Args:
        original_prompt: The original system prompt.
        failure_feedback: List of feedback from failures.

    Returns:
        AdaptedPrompt with improvements.
    """
    if not failure_feedback:
        return AdaptedPrompt(
            original_prompt=original_prompt,
            adapted_prompt=original_prompt,
            learnings_applied=[],
        )

    feedback_text = "\n".join(f"- {f}" for f in failure_feedback[-5:])

    result = await prompt_adapter_agent.run(
        f"Original system prompt:\n{original_prompt}\n\n"
        f"Failure feedback patterns:\n{feedback_text}\n\n"
        f"Create an improved prompt that addresses these issues."
    )

    return result.output


async def run_adaptive_task(
    task_type: str,
    input_text: str,
    feedback_loop: FeedbackLoop,
    record_outcome: bool = False,
    success: bool | None = None,
    feedback: str = "",
) -> str:
    """
    Run a task with adaptive learning.

    Args:
        task_type: Type of task to perform.
        input_text: Input for the task.
        feedback_loop: Feedback loop for learning.
        record_outcome: Whether to record the outcome.
        success: Whether the outcome was successful (if recording).
        feedback: Feedback about the outcome (if recording).

    Returns:
        Task output string.
    """
    # Check if adaptation is needed
    if feedback_loop.should_adapt(task_type):
        suggestions = feedback_loop.get_improvement_suggestions(task_type)
        print(f"  Adaptation suggested, {len(suggestions)} patterns found")

    # Run with learning
    output, _ = await run_with_learning(
        task_type=task_type,
        input_text=input_text,
        store=feedback_loop.store,
    )

    # Record outcome if requested
    if record_outcome and success is not None:
        feedback_loop.record_outcome(
            task_type=task_type,
            input_text=input_text,
            output_text=output,
            success=success,
            feedback=feedback,
        )
        print(f"  Outcome recorded: {'success' if success else 'failure'}")

    return output


# --8<-- [end:learning]


if __name__ == "__main__":
    import asyncio

    async def main() -> None:
        print("=" * 60)
        print("DEMO: Learning and Adaptation Pattern")
        print("=" * 60)

        # Create experience store and feedback loop
        store = ExperienceStore()
        loop = FeedbackLoop(store=store)

        # Pre-populate with some examples
        store.add_success(
            task_type="summarize",
            input_text="Python is a programming language.",
            output_text="Python: A versatile programming language.",
        )
        store.add_success(
            task_type="summarize",
            input_text="Machine learning is a subset of AI.",
            output_text="ML: An AI subset focusing on learning from data.",
        )

        # Run a task with few-shot learning
        print("\n--- Running with Few-Shot Learning ---")
        output = await run_adaptive_task(
            task_type="summarize",
            input_text="Async programming improves concurrency.",
            feedback_loop=loop,
            record_outcome=True,
            success=True,
        )
        print(f"Output: {output}")

        # Show learning stats
        stats = loop.get_stats()
        print("\n--- Learning Statistics ---")
        print(f"Total experiences: {stats.total_experiences}")
        print(f"Successes: {stats.successes}")
        print(f"Success rate: {stats.success_rate:.2%}")
        print(f"Task types: {stats.task_types}")

    asyncio.run(main())
